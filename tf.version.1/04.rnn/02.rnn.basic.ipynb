{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 기본예제\n",
    "\n",
    "* 일부 코드 [김성훈 교수님 TensorFlow 강의자료](https://github.com/hunkim/DeepLearningZeroToAll) 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "rnn = tf.contrib.rnn\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23348727/cc981856-fce7-11e6-83ea-4b187473466b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: 2, state size: 2\n",
      "x_data: [[[1. 0. 0. 0.]]]\n",
      "outputs: [[[-0.55518246 -0.5669185 ]]]\n",
      "state: [[-0.55518246 -0.5669185 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('one_cell', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2)\n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    print(\"output size: {}, state size: {}\".format(cell.output_size, cell.state_size))\n",
    "\n",
    "    x_data = np.array([[h]], dtype=np.float32) # x_data = [[[1,0,0,0]]]\n",
    "    print(\"x_data: {}\".format(x_data))\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: {}\".format(outputs_))\n",
    "    print(\"state: {}\".format(state_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23383634/649efd0a-fd82-11e6-925d-8041242743b0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape: (1, 5, 4)\n",
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]]\n",
      "outputs: \n",
      "[[[ 0.2502348   0.6181834 ]\n",
      "  [ 0.55891544  0.2544017 ]\n",
      "  [-0.42626688  0.49625376]\n",
      "  [ 0.05493243  0.7646796 ]\n",
      "  [ 0.73394966 -0.3102551 ]]]\n",
      "state: [[ 0.73394966 -0.3102551 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('add_sequances', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicRNNCell(num_units=hidden_size)\n",
    "\n",
    "    x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
    "    print(\"x_data shape: {}\".format(x_data.shape))\n",
    "    print(\"x_data: {}\".format(x_data))\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: \\n{}\".format(outputs_))\n",
    "    print(\"state: {}\".format(state_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`tf.nn.static_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn)\n",
    "\n",
    "* `tf.nn.static_rnn` low level code\n",
    "\n",
    "```python\n",
    "state = cell.zero_state(...)\n",
    "outputs = []\n",
    "for input_ in inputs:\n",
    "  output, state = cell(input_, state)\n",
    "  outputs.append(output)\n",
    "return (outputs, state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23383681/9943a9fc-fd82-11e6-8121-bd187994e249.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-e3d4e4c304b1>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "outputs: \n",
      "[[[-0.04200047 -0.07450665]\n",
      "  [ 0.00470946 -0.04139847]\n",
      "  [-0.02686612  0.00093464]\n",
      "  [-0.04474749  0.0348079 ]\n",
      "  [-0.04594119 -0.06795195]]\n",
      "\n",
      " [[ 0.04210941  0.0022138 ]\n",
      "  [ 0.01712591 -0.10112297]\n",
      "  [-0.02285778 -0.03712514]\n",
      "  [-0.04265621  0.00582262]\n",
      "  [-0.05383435  0.03949804]]\n",
      "\n",
      " [[-0.02910151  0.03234435]\n",
      "  [-0.04585794  0.05841699]\n",
      "  [ 0.00604393  0.05195517]\n",
      "  [ 0.04733184  0.04134284]\n",
      "  [-0.00534663  0.06012887]]]\n",
      "\n",
      "memory cell state: \n",
      "[[-0.0788601  -0.12787348]\n",
      " [-0.13339275  0.08232088]\n",
      " [-0.01353076  0.12351479]]\n",
      "hidden cell state: \n",
      "[[-0.04594119 -0.06795195]\n",
      " [-0.05383435  0.03949804]\n",
      " [-0.00534663  0.06012887]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('3_batches_LSTM', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: \\n{}\\n\".format(outputs_))\n",
    "    #print(\"memory cell state: \\n{}\".format(state_[0])) # print memory cell\n",
    "    #print(\"hidden cell state: \\n{}\".format(state_[1])) # print hidden state\n",
    "    print(\"memory cell state: \\n{}\".format(state_.c)) # print memory cell\n",
    "    print(\"hidden cell state: \\n{}\".format(state_.h)) # print hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: \n",
      "[[[-0.2626353  -0.10113645]\n",
      "  [ 0.05246437 -0.09292916]\n",
      "  [ 0.10953575  0.1032918 ]\n",
      "  [ 0.17181712  0.21941169]\n",
      "  [ 0.03649883  0.28476456]]\n",
      "\n",
      " [[ 0.246008   -0.01989472]\n",
      "  [ 0.06693815  0.09941221]\n",
      "  [ 0.13537657  0.22427194]\n",
      "  [ 0.2024049   0.2932141 ]\n",
      "  [ 0.26339865  0.32779714]]\n",
      "\n",
      " [[ 0.07086135  0.17298564]\n",
      "  [ 0.14426777  0.2706858 ]\n",
      "  [ 0.38182002  0.21391447]\n",
      "  [ 0.5190277   0.15779868]\n",
      "  [ 0.52004856  0.19371179]]]\n",
      "\n",
      "hidden cell state: \n",
      "[[0.03649883 0.28476456]\n",
      " [0.26339865 0.32779714]\n",
      " [0.52004856 0.19371179]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('3_batches_GRU', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = rnn.GRUCell(num_units=hidden_size)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: \\n{}\\n\".format(outputs_))\n",
    "    print(\"hidden cell state: \\n{}\".format(state_)) # print hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: \n",
      "[[[ 0.11871063  0.05536252]\n",
      "  [ 0.02785934  0.05481167]\n",
      "  [-0.06707699  0.00771322]\n",
      "  [-0.1609556  -0.05433674]\n",
      "  [-0.25996542  0.04671576]]\n",
      "\n",
      " [[-0.03984005 -0.01051588]\n",
      "  [-0.16625214  0.06778486]\n",
      "  [-0.22376214  0.04054031]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]]\n",
      "\n",
      " [[-0.10502876 -0.0526636 ]\n",
      "  [-0.19158715 -0.11802494]\n",
      "  [-0.14602473 -0.1404725 ]\n",
      "  [-0.16414692 -0.15892558]\n",
      "  [ 0.          0.        ]]]\n",
      "\n",
      "memory cell state: \n",
      "[[-0.42165747  0.12546143]\n",
      " [-0.41787526  0.06052474]\n",
      " [-0.5189897  -0.25719088]]\n",
      "hidden cell state: \n",
      "[[-0.25996542  0.04671576]\n",
      " [-0.22376214  0.04054031]\n",
      " [-0.16414692 -0.15892558]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('3_batches_dynamic_length', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data, sequence_length=[5,3,4], dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: \\n{}\\n\".format(outputs_))\n",
    "    print(\"memory cell state: \\n{}\".format(state_.c)) # print memory cell\n",
    "    print(\"hidden cell state: \\n{}\".format(state_.h)) # print hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: \n",
      "[[[-0.0923196  -0.05381259]\n",
      "  [-0.17942934  0.02550524]\n",
      "  [-0.1008595  -0.02589609]\n",
      "  [-0.06396154 -0.07645492]\n",
      "  [ 0.04206917 -0.15921205]]\n",
      "\n",
      " [[-0.09433518  0.06279369]\n",
      "  [ 0.02118034 -0.07592113]\n",
      "  [ 0.01709709 -0.13287519]\n",
      "  [ 0.01941351 -0.16250803]\n",
      "  [ 0.02178395 -0.18334514]]\n",
      "\n",
      " [[ 0.00457918 -0.06666386]\n",
      "  [ 0.00937748 -0.11540769]\n",
      "  [-0.08648608 -0.03240742]\n",
      "  [-0.15848157  0.03932928]\n",
      "  [-0.08878244 -0.01559131]]]\n",
      "\n",
      "memory cell state: \n",
      "[[ 0.0682736  -0.31723994]\n",
      " [ 0.046914   -0.30664766]\n",
      " [-0.19359842 -0.02521864]]\n",
      "hidden cell state: \n",
      "[[ 0.04206917 -0.15921205]\n",
      " [ 0.02178395 -0.18334514]\n",
      " [-0.08878244 -0.01559131]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('initial_state', reuse=tf.AUTO_REUSE) as scope:\n",
    "    batch_size = 3\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                      [e, o, l, l, l],\n",
    "                      [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "    # One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch: 3\n",
    "    hidden_size=2\n",
    "    cell = rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x_data,\n",
    "                                       initial_state=initial_state,\n",
    "                                       dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"outputs: \\n{}\\n\".format(outputs_))\n",
    "    print(\"memory cell state: \\n{}\".format(state_.c)) # print memory cell\n",
    "    print(\"hidden cell state: \\n{}\".format(state_.h)) # print hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]\n",
      "  [ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]\n",
      "  [12. 13. 14.]]\n",
      "\n",
      " [[15. 16. 17.]\n",
      "  [18. 19. 20.]\n",
      "  [21. 22. 23.]\n",
      "  [24. 25. 26.]\n",
      "  [27. 28. 29.]]\n",
      "\n",
      " [[30. 31. 32.]\n",
      "  [33. 34. 35.]\n",
      "  [36. 37. 38.]\n",
      "  [39. 40. 41.]\n",
      "  [42. 43. 44.]]]\n"
     ]
    }
   ],
   "source": [
    "# Create new input data\n",
    "batch_size=3\n",
    "sequence_length=5\n",
    "input_dim=3\n",
    "\n",
    "x_data = np.arange(45, dtype=np.float32).reshape(batch_size, sequence_length, input_dim)\n",
    "print(x_data)  # [batch, sequence_length, input_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-directional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bidirectional_rnn](https://user-images.githubusercontent.com/11681225/46912324-3d53e400-cfad-11e8-8b09-85d8ebdb0e66.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional RNN with basic RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foward outputs: shape (3, 5, 4)\n",
      "[[[-0.372043   -0.05765534  0.49066675  0.5124193 ]\n",
      "  [-0.19166756 -0.6246104   0.42906988  0.6761464 ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9890785  -0.9969672   0.66415185  0.85173994]\n",
      "  [ 0.97311914 -0.9996541  -0.23717575  0.8176195 ]\n",
      "  [ 0.995216   -0.99970293 -0.2903907   0.6522441 ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9999724  -0.99999475  0.7869898   0.9610064 ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "\n",
      "forward hidden cell state: \n",
      "[[-0.19166756 -0.6246104   0.42906988  0.6761464 ]\n",
      " [ 0.995216   -0.99970293 -0.2903907   0.6522441 ]\n",
      " [ 0.9999724  -0.99999475  0.7869898   0.9610064 ]]\n",
      "\n",
      "backward outputs: shape (3, 5, 4)\n",
      "[[[ 8.2217342e-01  8.8321394e-01  8.8896561e-01  4.0792650e-01]\n",
      "  [ 9.9968851e-01  6.0219079e-01  9.9995232e-01 -4.0174642e-01]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 1.0000000e+00 -4.4341749e-04  1.0000000e+00 -2.4021873e-01]\n",
      "  [ 1.0000000e+00  4.6232909e-02  1.0000000e+00  9.9916175e-02]\n",
      "  [ 1.0000000e+00 -3.0178553e-01  1.0000000e+00 -7.6224834e-01]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 1.0000000e+00 -6.7262065e-01  1.0000000e+00 -8.5898870e-01]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "backward hidden cell state: \n",
      "[[ 8.2217342e-01  8.8321394e-01  8.8896561e-01  4.0792650e-01]\n",
      " [ 1.0000000e+00 -4.4341749e-04  1.0000000e+00 -2.4021873e-01]\n",
      " [ 1.0000000e+00 -6.7262065e-01  1.0000000e+00 -8.5898870e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('bi-directional_RNN', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # bi-directional rnn\n",
    "    cell_fw = rnn.BasicRNNCell(num_units=4)\n",
    "    cell_bw = rnn.BasicRNNCell(num_units=4)\n",
    "\n",
    "    # x_data.shape = (3, 5, 3) [batch, sequence_length, input_dim]\n",
    "    # outputs.shape = two element tuple of (3, 5, 4) [batch, sequence_length, input_dim] shape\n",
    "        # outputs[0]: cell_fw, outputs[1]: cell_bw\n",
    "    # state.shape = two element tuple (3, 4) [batch, sequence_length, input_dim]\n",
    "        # states[0]: cell_fw, states[1]: cell_bw\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x_data,\n",
    "                                                      sequence_length=[2, 3, 1],\n",
    "                                                      dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, states_ = sess.run([outputs, states])\n",
    "    print(\"foward outputs: shape {}\\n{}\\n\".format(outputs_[0].shape, outputs_[0]))\n",
    "    print(\"forward hidden cell state: \\n{}\\n\".format(states_[0]))\n",
    "    print(\"backward outputs: shape {}\\n{}\\n\".format(outputs_[1].shape, outputs_[1]))\n",
    "    print(\"backward hidden cell state: \\n{}\".format(states_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional RNN with basic LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foward outputs: shape: (3, 5, 4)\n",
      "[[[ 2.6394698e-01  1.2007784e-01 -2.1567455e-01 -1.0304569e-01]\n",
      "  [ 4.2820162e-01  4.9870023e-01 -6.6084749e-01 -3.0921070e-02]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 6.0132229e-01  7.0859015e-01 -7.6147884e-01 -9.8406803e-09]\n",
      "  [ 4.6547440e-01  8.6408085e-01 -7.6157928e-01 -2.7965594e-09]\n",
      "  [ 4.8547259e-01  8.9369202e-01 -7.6159167e-01 -5.1230581e-10]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 6.6101509e-01  7.5673598e-01 -7.6159418e-01 -3.0194975e-16]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "forward memory cell state: \n",
      "[[ 6.3424301e-01  9.9295974e-01 -9.0144968e-01 -2.6529068e-01]\n",
      " [ 5.3074723e-01  1.5165038e+00 -9.9999684e-01 -8.8959314e-05]\n",
      " [ 7.9464942e-01  9.9999964e-01 -1.0000000e+00 -1.6330908e-08]]\n",
      "forward hidden cell state: \n",
      "[[ 4.2820162e-01  4.9870023e-01 -6.6084749e-01 -3.0921070e-02]\n",
      " [ 4.8547259e-01  8.9369202e-01 -7.6159167e-01 -5.1230581e-10]\n",
      " [ 6.6101509e-01  7.5673598e-01 -7.6159418e-01 -3.0194975e-16]]\n",
      "\n",
      "backward outputs: shape: (3, 5, 4)\n",
      "[[[ 3.2034749e-01  3.7117675e-01 -4.3194771e-01  8.4559917e-02]\n",
      "  [ 4.9782431e-01  2.6925904e-01 -3.2700136e-01  3.2024294e-02]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 7.5815403e-01  1.1316800e-02 -8.4961969e-01 -1.3370984e-02]\n",
      "  [ 7.6010674e-01  3.5905547e-03 -8.1489301e-01 -6.6287736e-03]\n",
      "  [ 7.6087868e-01  8.9229888e-04 -6.2365133e-01 -2.3724795e-03]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 7.6156151e-01  3.6692538e-05 -6.8484175e-01 -2.6764054e-04]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "backward memory cell state: \n",
      "[[ 9.0102005e-01  5.2583581e-01 -7.5190043e-01  1.8177475e-01]\n",
      " [ 1.0021330e+00  1.1366583e-02 -1.8567147e+00 -7.3787111e-01]\n",
      " [ 1.0000000e+00  3.6696048e-05 -8.7709731e-01 -8.9791715e-01]]\n",
      "backward hidden cell state: \n",
      "[[ 3.2034749e-01  3.7117675e-01 -4.3194771e-01  8.4559917e-02]\n",
      " [ 7.5815403e-01  1.1316800e-02 -8.4961969e-01 -1.3370984e-02]\n",
      " [ 7.6156151e-01  3.6692538e-05 -6.8484175e-01 -2.6764054e-04]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('bi-directional_LSTM', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # bi-directional rnn\n",
    "    cell_fw = rnn.BasicLSTMCell(num_units=4, state_is_tuple=True)\n",
    "    cell_bw = rnn.BasicLSTMCell(num_units=4, state_is_tuple=True)\n",
    "\n",
    "    # x_data.shape = (3, 5, 3) [batch, sequence_length, input_dim]\n",
    "    # outputs.shape = two element tuple of (3, 5, 4) [batch, sequence_length, input_dim] shape\n",
    "        # outputs[0]: cell_fw, outputs[1]: cell_bw\n",
    "    # state.shape = two element tuple (3, 4) [batch, sequence_length, input_dim]\n",
    "        # states[0]: cell_fw, states[1]: cell_bw\n",
    "    outputs, state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x_data,\n",
    "                                                      sequence_length=[2, 3, 1],\n",
    "                                                      dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, state_ = sess.run([outputs, state])\n",
    "    print(\"foward outputs: shape: {}\\n{}\\n\".format(outputs_[0].shape, outputs_[0]))\n",
    "    print(\"forward memory cell state: \\n{}\".format(state_[0].c))\n",
    "    print(\"forward hidden cell state: \\n{}\\n\".format(state_[0].h))\n",
    "    print(\"backward outputs: shape: {}\\n{}\\n\".format(outputs_[1].shape, outputs_[1]))\n",
    "    print(\"backward memory cell state: \\n{}\".format(state_[1].c))\n",
    "    print(\"backward hidden cell state: \\n{}\".format(state_[1].h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multilayer_rnn](https://user-images.githubusercontent.com/11681225/46912330-5fe5fd00-cfad-11e8-95c2-94bb8e7b1bf6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer RNN with basic RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: shape: (3, 5, 4)\n",
      "[[[-0.07938521 -0.08045461 -0.11057801 -0.548945  ]\n",
      "  [-0.3779834  -0.4411604  -0.4776888  -0.51664066]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.003076    0.08089301 -0.62068415 -0.81495845]\n",
      "  [-0.33286124 -0.59247947 -0.8774056  -0.43668047]\n",
      "  [-0.7140866  -0.18756755 -0.76010275 -0.8602962 ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.00220012  0.09204233 -0.64357686 -0.8245329 ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "\n",
      "Number of Layers: 3\n",
      "Layer 1 hidden cell state: \n",
      "[[-0.9338281   0.93689495  0.2938209   0.99999374]\n",
      " [-0.9998581   1.          0.9578909   1.        ]\n",
      " [-0.99996024  1.          0.9839632   1.        ]]\n",
      "\n",
      "Layer 2 hidden cell state: \n",
      "[[ 0.8945424  -0.6959408   0.39896905 -0.1898618 ]\n",
      " [ 0.88989204 -0.8245196   0.7478158   0.06878422]\n",
      " [ 0.86615837 -0.78391284  0.709893    0.40904027]]\n",
      "\n",
      "Layer 3 hidden cell state: \n",
      "[[-0.3779834  -0.4411604  -0.4776888  -0.51664066]\n",
      " [-0.7140866  -0.18756755 -0.76010275 -0.8602962 ]\n",
      " [-0.00220012  0.09204233 -0.64357686 -0.8245329 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('MultiRNN_RNN', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # MultiLayer RNN\n",
    "    num_layers = 3\n",
    "    multi_cells = rnn.MultiRNNCell([rnn.BasicRNNCell(4) for _ in range(num_layers)])\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(multi_cells, x_data,\n",
    "                                        sequence_length=[2, 3, 1],\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, states_ = sess.run([outputs, states])\n",
    "    print(\"outputs: shape: {}\\n{}\\n\".format(outputs_.shape, outputs_))\n",
    "    print(\"Number of Layers: {}\".format(len(states_))) \n",
    "    for i in range(num_layers):\n",
    "      print(\"Layer {} hidden cell state: \\n{}\\n\".format(i+1, states_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer RNN with basic LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: shape: (3, 5, 4)\n",
      "[[[ 2.0920197e-03  6.5658655e-04 -8.4803137e-04  2.3442516e-03]\n",
      "  [ 6.3524595e-03  3.9691618e-03 -3.4972571e-04  8.2148211e-03]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 1.4048272e-04 -1.5914498e-03 -1.6979526e-03  8.0133528e-03]\n",
      "  [-9.6788845e-04 -4.4106226e-03 -3.9039277e-03  2.2062376e-02]\n",
      "  [-2.7877118e-03 -6.8882983e-03 -5.3026089e-03  3.9211988e-02]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 8.1796010e-05 -1.6882729e-03 -1.7611167e-03  8.1220046e-03]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "Number of Layers: 3\n",
      "Layer 1 memory cell state: \n",
      "[[ 5.8990348e-02 -7.8239065e-01  5.4328841e-01 -3.1020632e-01]\n",
      " [ 1.8025398e-03 -2.9708686e+00  2.9569151e+00 -1.5606365e-05]\n",
      " [ 1.9442339e-06 -9.9992698e-01  9.9934518e-01 -4.5507797e-08]]\n",
      "\n",
      "Layer 1 hidden cell state: \n",
      "[[ 4.5214452e-02 -5.3001553e-01  1.1493550e-01 -4.8437040e-02]\n",
      " [ 1.7669713e-03 -9.9289447e-01  3.5848698e-04 -6.1857634e-08]\n",
      " [ 1.9369029e-06 -7.6149619e-01  6.3981142e-06 -3.4595254e-11]]\n",
      "\n",
      "Layer 2 memory cell state: \n",
      "[[-0.10474108  0.04445697  0.02023215 -0.03367297]\n",
      " [-0.35078105  0.41115892  0.25179994 -0.14689294]\n",
      " [-0.10437831  0.13119958  0.07756271 -0.05196612]]\n",
      "\n",
      "Layer 2 hidden cell state: \n",
      "[[-0.04987432  0.02498464  0.01036293 -0.0179524 ]\n",
      " [-0.15221445  0.23129061  0.1291657  -0.07982457]\n",
      " [-0.04638587  0.07351763  0.04023837 -0.02815024]]\n",
      "\n",
      "Layer 3 memory cell state: \n",
      "[[ 0.01255895  0.0078977  -0.0007044   0.01640199]\n",
      " [-0.00526524 -0.0135706  -0.01126814  0.07592165]\n",
      " [ 0.00016074 -0.00336792 -0.00359208  0.0160799 ]]\n",
      "\n",
      "Layer 3 hidden cell state: \n",
      "[[ 6.3524595e-03  3.9691618e-03 -3.4972571e-04  8.2148211e-03]\n",
      " [-2.7877118e-03 -6.8882983e-03 -5.3026089e-03  3.9211988e-02]\n",
      " [ 8.1796010e-05 -1.6882729e-03 -1.7611167e-03  8.1220046e-03]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  with tf.variable_scope('MultiRNN_LSTM', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # MultiLayer RNN\n",
    "    def lstm_cell(hidden_size):\n",
    "      cell = rnn.BasicLSTMCell(\n",
    "          num_units=hidden_size, state_is_tuple=True)\n",
    "      return cell\n",
    "\n",
    "    num_layers = 3\n",
    "    multi_cells = rnn.MultiRNNCell([lstm_cell(4) for _ in range(num_layers)],\n",
    "                                   state_is_tuple=True)\n",
    "    outputs, states = tf.nn.dynamic_rnn(multi_cells, x_data,\n",
    "                                        sequence_length=[2, 3, 1],\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_, states_ = sess.run([outputs, states])\n",
    "    print(\"outputs: shape: {}\\n{}\\n\".format(outputs_.shape, outputs_))\n",
    "    print(\"Number of Layers: {}\".format(len(states_))) \n",
    "    for i in range(num_layers):\n",
    "      print(\"Layer {} memory cell state: \\n{}\\n\".format(i+1, states_[i].c))\n",
    "      print(\"Layer {} hidden cell state: \\n{}\\n\".format(i+1, states_[i].h))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
