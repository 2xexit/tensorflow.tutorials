{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guide to TF Layers: Building a Convolutional Neural Network\n",
    "\n",
    "* [MNIST tutorials](https://www.tensorflow.org/tutorials/layers)\n",
    "<img src=\"https://user-images.githubusercontent.com/11681225/46912292-54460680-cfac-11e8-89a3-d8d1a4ec13ae.png\" width=\"20%\">\n",
    "\n",
    "* training dataset: 60000\n",
    "* test dataset: 10000\n",
    "* one example: gray scale image with $28 \\times 28$ size\n",
    "* [`cnn_mnist.py`](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/examples/tutorials/layers/cnn_mnist.py) 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab4all/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "\n",
    "* Convolutional layers\n",
    "  * $\\textrm{ReLU}({\\bf x} * {\\bf w} + {\\bf b})$\n",
    "  * $*$: convolution operator\n",
    "* Pooling layers\n",
    "  * down sampling: `max-pooling`, `average-pooling`\n",
    "* Dense (fully connected) layers\n",
    "  * $\\textrm{ReLU}({\\bf w} {\\bf x} + {\\bf b})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of LeNet 5\n",
    "\n",
    "<img width=\"90%\" alt=\"lenet5\" src=\"https://user-images.githubusercontent.com/11681225/46912300-a0914680-cfac-11e8-92fb-f1817267b4e4.png\">\n",
    "\n",
    "\n",
    "* Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "* Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "* Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
    "* Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "* Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "* Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0–9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model with `tf.layers` APIs\n",
    "\n",
    "* [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers) 링크\n",
    "* [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n",
    "* `tf.layers.max_pooling2d()`\n",
    "* `tf.layers.dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(219)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                  pool_size=[2, 2],\n",
    "                                  strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                  pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat,\n",
    "                          units=1024,\n",
    "                          activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4,\n",
    "    training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "    labels=labels,\n",
    "    logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer\n",
    "\n",
    "* 4-rank Tensor: `[batch_size, image_height, image_width, channels]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d layer\n",
    "\n",
    "* [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.conv2d(\n",
    "        inputs,\n",
    "        filters,\n",
    "        kernel_size)\n",
    "```\n",
    "* `inputs`: 4-rank Tensor: `[batch_size, image_height, image_width, channels]`\n",
    "* `filters`: output filter의 갯수\n",
    "* `kernel_size`: `[height, width]`\n",
    "* `padding`: `\"valid\"` or `\"same\"` (case-insensitive)\n",
    "  * `valid`: [32 x 32] -> [28 x 28] (`kernel_size`: 5)\n",
    "  * `same`: [32 x 32] -> [32 x 32] (`kernel_size`: 5)\n",
    "* `activation`\n",
    "  * 기본값이 None\n",
    "  * `tf.nn.relu`를 습관적으로 해주는게 좋음 (맨 마지막 레이어를 제외하고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maxpooling2d layer\n",
    "\n",
    "* [`tf.layers.maxpooling2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.maxpooling2d(\n",
    "        inputs,\n",
    "        pool_size,\n",
    "        strides)\n",
    "```\n",
    "* `inputs`: 4-rank Tensor: `[batch_size, image_height, image_width, channels]`\n",
    "* `pool_size`: `[height, width]`\n",
    "* `strides`: `[height, width]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense layer\n",
    "\n",
    "* [`tf.layers.dense()`](https://www.tensorflow.org/api_docs/python/tf/layers/dense) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.dense(\n",
    "        inputs,\n",
    "        units)\n",
    "```\n",
    "* `inputs`: 2-rank Tensor: `[batch_size, features]`\n",
    "* `units`: output node 갯수\n",
    "* `conv2d`나 `maxpooling2d` 뒤에 `dense`레이어를 쓰려면 `inputs` 텐서의 차원을 맞춰줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout layer\n",
    "\n",
    "* [`tf.layers.dropout()`](https://www.tensorflow.org/api_docs/python/tf/layers/dropout) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.dropout(\n",
    "        inputs\n",
    "        rate=0.5,\n",
    "        training=False)\n",
    "```\n",
    "* `inputs`: 2-rank Tensor: `[batch_size, features]`\n",
    "* `rate`: dropout rate\n",
    "* `training`: `training` mode인지 아닌지 구분해주는 `argument`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logits layer\n",
    "\n",
    "* `softmax`를 하기 전에 score 값(raw value)을 전달해 주는 `layer`\n",
    "* `activation`을 하지 않는게 중요\n",
    "* `units`갯수는 class 갯수와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate predictions\n",
    "\n",
    "* `predicted class` for each example\n",
    "  * [`tf.argmax`](https://www.tensorflow.org/api_docs/python/tf/argmax) 사용\n",
    "* `probabilities` for each possible target class for each example\n",
    "  * [`tf.nn.softmax`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate loss\n",
    "\n",
    "* multiclass classification problems\n",
    "  * `cross_entropy` loss: $- \\sum y \\log \\hat{y}$\n",
    "  * `tf.losses.softmax_cross_entropy` API 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Training Op\n",
    "\n",
    "* stochastic gradient descent\n",
    "* [Optimizers API](https://www.tensorflow.org/api_guides/python/train#Optimizers)\n",
    "```\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "      loss=loss,\n",
    "      global_step=tf.train.get_global_step())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add evaluation metrics\n",
    "\n",
    "```\n",
    "eval_metric_ops = {\n",
    "    \"accuracy\": tf.metrics.accuracy(\n",
    "        labels=labels, predictions=predictions[\"classes\"])}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'graphs/01.1.mnist.deep.with.estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f70a9bf2630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"graphs/01.1.mnist.deep.with.estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into graphs/01.1.mnist.deep.with.estimator/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.09946432 0.10026968 0.1001089  0.1088763  0.09241221 0.10655838\n",
      "  0.09769787 0.09167217 0.09558441 0.10735577]\n",
      " [0.10443639 0.09028919 0.10932202 0.10557002 0.08750195 0.1129559\n",
      "  0.09283712 0.10187628 0.0911648  0.10404633]\n",
      " [0.08729037 0.08273202 0.11882669 0.10135613 0.09783328 0.10637151\n",
      "  0.08952356 0.11445157 0.09460464 0.10701024]\n",
      " [0.09924364 0.0940272  0.11895797 0.11179941 0.095858   0.09456187\n",
      "  0.0971493  0.09239972 0.0989261  0.09707679]\n",
      " [0.09159164 0.09455547 0.10412133 0.10369674 0.1053172  0.11078608\n",
      "  0.08988277 0.09075892 0.09818998 0.11109987]\n",
      " [0.10220621 0.10478947 0.11513246 0.09837164 0.09952052 0.09586844\n",
      "  0.09238272 0.08614958 0.1033251  0.10225387]\n",
      " [0.10435115 0.08502124 0.11360402 0.11627009 0.10421653 0.07908668\n",
      "  0.10017266 0.09677888 0.09226903 0.10822972]\n",
      " [0.09597888 0.10312434 0.11643726 0.11183302 0.09013544 0.09379151\n",
      "  0.09791595 0.08994972 0.101786   0.09904787]\n",
      " [0.10070019 0.09537416 0.10817888 0.10400781 0.08921426 0.10139185\n",
      "  0.09732563 0.09590693 0.10053729 0.10736299]\n",
      " [0.10097369 0.08559981 0.11647373 0.09710998 0.11096223 0.09809307\n",
      "  0.09966926 0.09172421 0.09826843 0.1011256 ]\n",
      " [0.1073066  0.08320223 0.11746835 0.09739469 0.09347554 0.10871083\n",
      "  0.08883403 0.09501409 0.09519454 0.1133991 ]\n",
      " [0.10177215 0.09340528 0.11782653 0.10845497 0.09039239 0.09269227\n",
      "  0.09705211 0.09940698 0.09431259 0.10468472]\n",
      " [0.09472759 0.09831738 0.11428047 0.097386   0.10131848 0.09048984\n",
      "  0.09880184 0.09486732 0.10088396 0.10892712]\n",
      " [0.09180987 0.0928457  0.1165526  0.10715163 0.08762308 0.10376589\n",
      "  0.09356718 0.10059953 0.10392332 0.10216121]\n",
      " [0.08955369 0.10699753 0.11197641 0.11143768 0.09347683 0.09268579\n",
      "  0.10307579 0.10078688 0.0940529  0.0959565 ]\n",
      " [0.09921379 0.10462101 0.11132558 0.09316675 0.1030828  0.08937568\n",
      "  0.08657999 0.10838888 0.09821129 0.10603424]\n",
      " [0.10244258 0.09564789 0.10778506 0.10975505 0.106875   0.09168886\n",
      "  0.0909107  0.09638418 0.09549439 0.1030163 ]\n",
      " [0.09609378 0.09586648 0.11672204 0.11088549 0.10076806 0.09421083\n",
      "  0.09578908 0.10100072 0.09233336 0.09633016]\n",
      " [0.09649631 0.08551136 0.1099404  0.09638389 0.10383239 0.09547519\n",
      "  0.09160494 0.09949061 0.09651641 0.12474849]\n",
      " [0.10346794 0.08839128 0.10054343 0.10188596 0.08987117 0.10823072\n",
      "  0.08881338 0.09907354 0.10427999 0.11544258]\n",
      " [0.08875466 0.0994645  0.10569302 0.1201     0.09718591 0.10174449\n",
      "  0.09322405 0.09604496 0.09420196 0.10358646]\n",
      " [0.10511659 0.08575994 0.12346674 0.10150193 0.10835783 0.0983972\n",
      "  0.09056212 0.09366892 0.07741928 0.11574944]\n",
      " [0.09267117 0.10042936 0.13061588 0.10450389 0.08431521 0.09645798\n",
      "  0.09670239 0.08722965 0.11208895 0.09498553]\n",
      " [0.10065306 0.09017275 0.11518088 0.11762844 0.09280955 0.0911362\n",
      "  0.08095194 0.09442486 0.10713613 0.10990619]\n",
      " [0.09394565 0.08985346 0.11212378 0.10498716 0.10118415 0.09886207\n",
      "  0.09555081 0.0967238  0.10504513 0.101724  ]\n",
      " [0.09407812 0.09125576 0.12090464 0.11018291 0.09829401 0.10944206\n",
      "  0.09311722 0.08155367 0.09620841 0.10496319]\n",
      " [0.09858521 0.09498974 0.12218548 0.10306892 0.10128729 0.08834141\n",
      "  0.0978213  0.08914431 0.09775096 0.10682539]\n",
      " [0.10073478 0.08376459 0.12327143 0.10664797 0.10707094 0.09321772\n",
      "  0.09472827 0.08829118 0.09255231 0.1097208 ]\n",
      " [0.10004572 0.09400966 0.11266176 0.11509873 0.0894834  0.10189326\n",
      "  0.08128142 0.10419193 0.098621   0.10271313]\n",
      " [0.09904058 0.07948872 0.10569061 0.11389015 0.09850022 0.09548512\n",
      "  0.10020493 0.10098993 0.10095176 0.10575798]\n",
      " [0.09992946 0.08734132 0.119345   0.10290474 0.09553966 0.09340845\n",
      "  0.09587583 0.07593315 0.10571575 0.12400662]\n",
      " [0.09959949 0.10225482 0.10163707 0.09984526 0.0931049  0.098772\n",
      "  0.09042643 0.09925439 0.10476501 0.11034064]]\n",
      "INFO:tensorflow:loss = 2.2849764823913574, step = 0\n",
      "INFO:tensorflow:probabilities = [[0.00071469 0.88378742 0.00988045 0.02692234 0.00397064 0.00166688\n",
      "  0.0047149  0.02902962 0.02255524 0.01675783]\n",
      " [0.00038087 0.00027421 0.00086893 0.00033509 0.00116583 0.00012064\n",
      "  0.99595497 0.00000276 0.00056764 0.00032906]\n",
      " [0.00158104 0.81652309 0.00983968 0.04126663 0.0100924  0.00384724\n",
      "  0.00625785 0.0421972  0.05406089 0.01433398]\n",
      " [0.00805815 0.04615101 0.2070233  0.12036946 0.1463691  0.00635101\n",
      "  0.03216287 0.28872888 0.05917311 0.0856131 ]\n",
      " [0.03292783 0.00214164 0.00882735 0.00365761 0.00385329 0.01035041\n",
      "  0.89718207 0.00018744 0.03889862 0.00197372]\n",
      " [0.00369211 0.00114682 0.00082114 0.00070347 0.85879826 0.00698872\n",
      "  0.00363326 0.02184934 0.04167163 0.06069525]\n",
      " [0.00074472 0.00034036 0.00029795 0.00016735 0.94778924 0.00241002\n",
      "  0.00537536 0.00328154 0.00385379 0.03573966]\n",
      " [0.06563547 0.25533355 0.16744409 0.19956709 0.00030638 0.11465162\n",
      "  0.01217871 0.00040578 0.18415565 0.00032167]\n",
      " [0.0065039  0.00439372 0.02387143 0.00421213 0.39658283 0.01418975\n",
      "  0.04611011 0.17952537 0.05672292 0.26788785]\n",
      " [0.00083857 0.00008928 0.00053233 0.01290346 0.00003678 0.00104617\n",
      "  0.00004849 0.97874104 0.00556042 0.00020347]\n",
      " [0.0002572  0.00030263 0.00050968 0.98875468 0.0007323  0.00282276\n",
      "  0.00027204 0.0000486  0.00616105 0.00013905]\n",
      " [0.00843908 0.01339357 0.01870025 0.01568277 0.00546382 0.00897354\n",
      "  0.86334977 0.00039211 0.06378552 0.00181959]\n",
      " [0.00415721 0.00508289 0.00082623 0.01129149 0.55395592 0.06351087\n",
      "  0.00569308 0.09014925 0.18453747 0.08079559]\n",
      " [0.40882228 0.00801822 0.01784449 0.07028126 0.00205883 0.02969943\n",
      "  0.11220379 0.00952552 0.33883759 0.0027086 ]\n",
      " [0.00043377 0.91722197 0.00354862 0.0236583  0.00074378 0.00121518\n",
      "  0.01113109 0.00435488 0.03309061 0.00460181]\n",
      " [0.00305453 0.01051536 0.00300807 0.01836511 0.22797061 0.01421636\n",
      "  0.00250888 0.58334768 0.07460209 0.06241133]\n",
      " [0.00056492 0.88936171 0.00824152 0.01823041 0.00430625 0.00203973\n",
      "  0.00365738 0.00850724 0.060791   0.00429982]\n",
      " [0.22534668 0.03283728 0.00861523 0.11155694 0.0025666  0.30111675\n",
      "  0.02953338 0.01171515 0.27343296 0.00327904]\n",
      " [0.00668545 0.10249254 0.00150725 0.07979958 0.30751007 0.02417905\n",
      "  0.05560253 0.03257583 0.08904878 0.30059892]\n",
      " [0.00173548 0.00063624 0.00012571 0.00234124 0.02846273 0.01670726\n",
      "  0.00017526 0.92887437 0.00432885 0.01661287]\n",
      " [0.00440716 0.00007796 0.00655984 0.00107676 0.00208015 0.00076178\n",
      "  0.98125882 0.00002303 0.00339758 0.00035691]\n",
      " [0.00001492 0.00010315 0.00108464 0.99096122 0.00000067 0.00062428\n",
      "  0.00000255 0.00015712 0.00704372 0.00000773]\n",
      " [0.01281157 0.00032204 0.00178622 0.58077007 0.00475734 0.13699823\n",
      "  0.00004797 0.0074183  0.25326012 0.00182814]\n",
      " [0.00218267 0.86143692 0.00336339 0.0242682  0.006077   0.00635016\n",
      "  0.02429159 0.00554386 0.05695024 0.00953596]\n",
      " [0.0168082  0.03518557 0.13438443 0.03294483 0.15971354 0.03014234\n",
      "  0.11298753 0.06306248 0.06991889 0.34485218]\n",
      " [0.20752388 0.02466695 0.01196533 0.07749532 0.00347423 0.10208875\n",
      "  0.00285796 0.00320266 0.56576024 0.00096467]\n",
      " [0.01678159 0.00021209 0.91326363 0.04123104 0.0011866  0.00027863\n",
      "  0.01028647 0.00002767 0.01663095 0.00010132]\n",
      " [0.01545273 0.00317935 0.0022821  0.02614023 0.00265069 0.02501683\n",
      "  0.80941004 0.00011744 0.11367351 0.00207707]\n",
      " [0.00024589 0.00009567 0.00062972 0.00138361 0.92667503 0.00201601\n",
      "  0.0024793  0.00177935 0.00127006 0.06342536]\n",
      " [0.0124856  0.00723813 0.02645864 0.01552289 0.01066328 0.0103987\n",
      "  0.88907818 0.00038545 0.02152863 0.00624049]\n",
      " [0.00255072 0.44883313 0.01903072 0.02553561 0.00144835 0.00210519\n",
      "  0.03414768 0.00079369 0.46511379 0.00044111]\n",
      " [0.00426599 0.00063226 0.06803767 0.02127275 0.14204719 0.00519288\n",
      "  0.72485    0.00263635 0.01203621 0.0190287 ]] (0.752 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into graphs/01.1.mnist.deep.with.estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.37314504384994507.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f70a9bf2198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=32,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-04-08:48:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from graphs/01.1.mnist.deep.with.estimator/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-04-08:48:03\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9118, global_step = 100, loss = 0.29634535\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: graphs/01.1.mnist.deep.with.estimator/model.ckpt-100\n",
      "{'accuracy': 0.9118, 'loss': 0.29634535, 'global_step': 100}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    y=test_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_results = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
